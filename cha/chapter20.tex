\chapter{截断法，辛钦弱大数定律}

我们今天来首先证明辛钦弱大数定律，需要引入一种称为“截断法”的技巧。我们再使用类似技巧来讨论我们\href{https://shuiyuan.sjtu.edu.cn/t/topic/308617}{\underline{第一次课}}提到的圣彼得堡悖论问题。

\section{辛钦大数定律}

我们回忆上节课提到过的辛钦弱大数定律：

\begin{theorem}[辛钦弱大数定律]
设 $X_1,X_2,\dots$ 是\textbf{独立同分布}的随机变量，并且每一个 $X_i$ 均是可积的，满足 $\E{X_i} = \mu$。那么 $\frac{S_n}{n} = \frac{\sum_{i\in [n]} X_i}{n}\overset{P}{\to} \mu$。
\end{theorem}

这个结论和我们之前证明过的弱大数定律主要有两点不同：
\begin{itemize}
\item 对随机变量列的要求加强为独立同分布，而在之前的结论里只要求独立；
    \item 对随机变量不要求二阶矩有界了。
\end{itemize}

注意到我们之前是使用的矩方法，也就是切比雪夫不等式证明的弱大数定律。在我们现在只知道每一个 $\E{X_i}$ 可积，即一阶矩有界的情况下是不够用的。比如说，我们不妨假设 $X_n>0$, 那么根据马尔科夫不等式
\[
    \Pr{\frac{S_n}{n}-\mu>a}\le \frac{\E{X_1}}{\mu+a} = \frac{\mu}{\mu+a}.
\]

不等式右边与 $n$ 没有关系，因此我们不能够得到依概率收敛的结果。

注意到这里主要的困难在于 $X_i$ 的二阶矩是无界的，因此我们不能使用切比雪夫不等式来加强上式，使得右边出现 $o_n(1)$ 项。我们接下来将介绍一个我很喜欢的证明。我们现在做这样一个操作：选一个数 $M>0$，把随机变量 $X_i$ 分成其绝对值 $\le M$ 和 $>M$ 的两部分之和。对于绝对值 $\le M$ 的那一部分，我们知道由于其绝对值不超过 $M$，二阶矩是有界的，所以我们可以用切比雪夫不等式控制。对于绝对值 $>M$ 的那一部分，我们尝试说明它取到这里的值的概率为零（即所谓零阶矩方法）。To this end，我们定义
\[
    X_i^{\le M}\defeq X_i\cdot\bb I_{\abs{X_i}\le M},\quad X_i^{>M}\defeq X_i\cdot \bb I_{\abs{X_i}>M}.
\]

于是 $X_i = X_i^{\le M} + X_i^{>M}$。我们同样定义
\[
    S_n^{\le M} = \sum_{i\in [n]}X_i^{\le M},\quad S_n^{>M}\defeq \sum_{i\in [n]} X_i^{>M}.
\]

于是 $S_n = S_n^{\le M}+S_n^{>M}$。对于常数 $\eps>0$，我们有
\[
\begin{aligned}
    \Pr{\abs{\frac{S_n}{n}-\mu}>\eps} 
    &= \Pr{\abs{\frac{S_n^{\le M}}{n}-\mu + \frac{S_n^{>M}}{n}}>\eps}\\
    &= \Pr{\abs{\frac{S_n^{\le M}}{n}-\mu + \frac{S_n^{>M}}{n}}>\eps \land S_n^{>M}=0} \\
&\quad\quad\quad+ \Pr{\abs{\frac{S_n^{\le M}}{n}-\mu + \frac{S_n^{>M}}{n}}>\eps\land S_n^{>M}\ne 0}\\
    &\le \Pr{\abs{\frac{S_n^{\le M}}{n}-\mu}>\eps} + \Pr{S_n^{>M}\ne 0}.
\end{aligned}
\]

按照我们刚才说的计划，我们需要选一个合适的 $M$，使得在 $n$ 趋向于无穷大的时候，上式两个概率均趋向于 $0$。显然，上式两个概率让我们需要仔细权衡 $M$ 的选择，因为 $M$ 越小，第一项 $\Pr{\abs{\frac{S_n^{\le M}}{n}-\mu}>\eps}$ 越小，而第二项 $\Pr{S_n^{>M}\ne 0}$ 越大。我们这儿令 $M=n$.

我们先来控制第一项 $\Pr{\abs{\frac{S_n^{\le n}}{n}-\mu}>\eps}$。首先有一个问题在于，我们不能够直接对这个式子使用切比雪夫不等式，原因在于虽然 $\E{\frac{S_n}{n}} = \mu$，但截断后的 $\mu_n\defeq \E{\frac{S_n^{\le n}}{n}}$ 就不一定是 $\mu$ 了。根据定义
\[
    \mu_n=\E{X_1^{\le n}} = \E{X_1\cdot \bb I_{\abs{X_i}\le n}}.
\]

我们注意到，对于任意 $n$，都有 $\abs{X_1^{\le n}}\le \abs{X_1}$。因此由 DCT，我们知道
\[
    \lim_{n\to\infty} \mu_n = \E{\lim_{n\to\infty}X_1^{\le n}} = \E{X_1} = \mu.
\]

换句话说，在 $n$ 足够大的时候 $\mu_n$ 和 $\mu$ 可以任意接近。因此，我们只需要证明
\[
    \lim_{n\to\infty} \Pr{\abs{\frac{S_n^{\le n}}{n}-\mu_n}>\frac{\eps}{2}} = 0 
\]

即可。对于每一个 $n$，我们使用切比雪夫不等式，可以得到
\[
\Pr{\abs{\frac{S_n^{\le n}}{n}-\mu_n}>\frac{\eps}{2}} \le \frac{\Var{X_1^{\le n}}}{n\eps^2} \le \frac{\E{\tp{X_1^{\le n}}^2}}{n\eps^2} = \eps^{-2}\E{\frac{X_1^2\cdot \bb I_{\abs{X_1}\le n}}{n}}.
\]

对于任意 $n$，我们都有 $\frac{X_1^2\cdot \bb I_{\abs{X_1}\le n}}{n}\le \abs{X_1}$。并且，$\lim_{n\to\infty} \frac{X_1^2\cdot \bb I_{\abs{X_1}\le n}}{n} = 0$ (逐点哦)。所以再次根据 DCT，
\[
    \lim_{n\to\infty} \Pr{\abs{\frac{S_n^{\le n}}{n}-\mu_n}>\frac{\eps}{2}} \le \eps^{-2}\E{\lim_{n\to\infty} \frac{X_1^2\cdot \bb I_{\abs{X_1}\le n}}{n}} = 0.
\]

接着我们来考虑第二项 $\Pr{S_n^{>n}\ne 0}$。由于 $S_n^{>n}\ne 0$ 的话必然对于某个 $i\in [n], X_i^{>n}\ne 0$。于是使用 union-bound，我们有
\[
  \Pr{S_n^{>n}\ne 0}\le \sum_{i\in [n]} \Pr{X_i^{>n}\ne 0} = n\cdot \Pr{X_1^{>n}\ne 0} = \E{n\cdot \bb I_{\abs{X_1}>n}}.
\]

注意到对于每一个 $n$，我们依旧有 $n\cdot \bb I_{\abs{X_1}>n} \le \abs{X_1}$。同时 $\lim_{n\to\infty} n\cdot \bb I_{\abs{X_1}>n}=0$ （还是逐点哦）。所以第三次使用 DCT，可以得到
\[
    \lim_{n\to\infty}\Pr{S_n^{>n}\ne 0}\le \E{\lim_{n\to\infty} n\cdot \bb I_{\abs{X_1}>n}} = 0.
\]

这便完成了证明。

如果大家仔细查看整个证明，特别是三次使用 DCT 时候需要验证的条件，会发现 $M=n$ 的选择似乎让两种情况的证明都“刚刚好”正确。整个证明过程如同在钢丝上跳舞，非常美妙。

\section{圣彼得堡悖论}

我们接着讨论第一次课提到过的圣彼得堡悖论。

\begin{leftbarquote}
假设有一个基于掷硬币赌博游戏。首先庄家扔一个公平硬币，如果结果是正面，则给玩家 $2$ 元钱，游戏结束；如果结果是反面，庄家再扔一次硬币，如果结果是正面，则给玩家 $4$ 元钱，游戏结束，否则按照同样的规则继续扔硬币，每一轮奖金翻倍。换句话说，庄家会生成一个无限长的投掷硬币的结果序列，如果这个序列里第一次正面是第 $k$ 个，则玩家获得 $2^k$ 元的奖金。现在的问题是，你愿意花多少钱去购买一次玩这个游戏的机会？或者说，假设你可以无限次的玩这个游戏，但是每一次需要付门票 $a$ 元，那你认为 $a$ 设置成多少是合理的？
\end{leftbarquote}

我们现在来这样建模这个问题。我们用 $X_i$ 表示第 $i$ 次游戏玩家能够得到的钱。那么 $S_n=\sum_{i\in [n]} X_i$ 就是玩了 $n$ 次游戏后的总收入。所有的 $X_i$ 都是独立同分布的。我们知道
\[
    \E{X_i} = \sum_{k=1}^\infty 2^k\cdot 2^{-k} = \infty.
\]

因此，我们不能用前面的辛钦大数定律来描述 $\frac{S_n}{n}$ 的行为。我们直观上 $\frac{S_n}{n}$ 应该是会发散到无穷大的。现在我们便用截断法来说明这一点。我们同样希望找到合适的 $\mu$ （和 $\eps$ ）使得 $\Pr{\abs{\frac{S_n}{n}-\mu}>\eps}$ 随着 $n$ 变大趋向于 $0$。使用和前面证明同样的记号和方法，我们有
\[
    \Pr{\abs{\frac{S_n}{n}-\mu}>\eps} \le \Pr{\abs{\frac{S_n^{\le M}}{n}-\mu}>\eps} + \Pr{S_n^{>M}\ne 0}.
\]

我们这儿为了方便设 $M=2^m$，其中 $m$ 是一个待定参数。我们同样想对上面的第一项使用切比雪夫不等式，于是计算
\[
    \E{\frac{S_n^{\le 2^m}}{n}} = \E{X_1^{\le 2^m}} = \sum_{k=1}^m 2^k\cdot 2^{-k} = m.
\]

于是我们可以选择 $\mu=m$，并且使用切比雪夫不等式得到
\[
    \Pr{\abs{\frac{S_n^{\le M}}{n}-m}>\eps}\le \frac{\Var{X_1^{\le 2^m}}}{n\eps^2}\le \frac{\E{\tp{X_1^{\le 2^m}}^2}}{n\eps^2}\le \frac{2^{m+1}}{n\eps^2},
\]

其中最后一个不等式是由于 $\E{\tp{X_1^{\le 2^m}}^2}=\sum_{k=1}^m 2^{2k}\cdot 2^{-k}\le 2^{m+1}$。

另一方面，我们依旧使用 union-bound，可以得到
\[
    \Pr{S_n^{>M}\ne 0}\le n\cdot \Pr{X_1^{>2^m}\ne 0} = n\cdot\sum_{k=m+1}^\infty 2^{-k} = n\cdot 2^{-m}.
\]

把这两项放在一起，我们得到了
\[
    \Pr{\abs{\frac{S_n}{n}-m}>\eps}\le \frac{2^{m+1}}{n\eps^2}+n\cdot 2^{-m}.
\]

我们因此又需要权衡截断的阈值 $M=2^m$。盯一会儿上式之后不难发现，我们可以取
\[
    \eps=\sqrt{\log_2 n},\quad m=\log_2 n+\frac{1}{2}\log_2\log_2 n.
\]

就能得到
\[
\Pr{\abs{\frac{S_n}{n}-\tp{\log_2 n+\frac{1}{2}\log_2\log_2 n}}>\sqrt{\log_2 n}} \le \frac{3}{\sqrt{\log_2 n}},
\]

即
\[
\Pr{\abs{\frac{S_n}{n\log_2 n}-(1+o(1))}>\frac{1}{\sqrt{\log_2 n}}}\le \frac{3}{\sqrt{\log_2 n}}.
\]

这说明，$\frac{S_n}{n}\overset{P}{\to}(1+o(1))\log_2 n$。这说明，如果游戏的门票是 $n$ 轮捆绑销售的话，每一轮 $\log_2n$ 的价格是一个合适的门票定价。

\newpage